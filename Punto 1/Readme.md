# üß† Maximizaci√≥n de la funci√≥n *f(x) = x¬≤ - 3x + 4*

Este ejercicio implementa tres algoritmos heur√≠sticos diferentes para **encontrar el m√°ximo global** de la funci√≥n dentro de un intervalo definido (-50,50), y compara sus resultados gr√°ficamente.

---

## üìò objetivo

La funci√≥n \( f(x) = x^2 - 3x + 4 \) es una par√°bola convexa hacia arriba (m√≠nimo en \(x = 1.5\)), en la cual buscamos el **m√°ximo global** en un intervalo finito, por ejemplo \([-50, 50]\).

El c√≥digo implementa y compara tres m√©todos:

1. **Hill Climbing:**  
   Explora el entorno del punto actual y acepta movimientos que mejoran la soluci√≥n.
2. **Greedy Search:**  
   Eval√∫a varios candidatos por iteraci√≥n y siempre elige el mejor.
3. **Algoritmo Gen√©tico (GA):**  
   Usa una poblaci√≥n de soluciones, selecci√≥n, cruce y con dos tasas de mutaci√≥n distintas (0.05 y 0.2).  
   Adem√°s, muestra la **curva de convergencia del fitness** a lo largo de las generaciones.


El programa genera dos gr√°ficos:

### 1. Comparaci√≥n de m√©todos heur√≠sticos
Muestra la funci√≥n \(f(x)\) con los puntos explorados por cada algoritmo:
- üîµ **Hill Climbing**
- üü¢ **Greedy Search**
- üî¥ **Algoritmo Gen√©tico**

[Punto_1_comparacion_metodos.png](https://github.com/RogueOne-22/Laboratorio_3/blob/19824c6ea6d83e5b6d96c2f70c8a974ba5beee73/Punto%201/Punto_1_comparacion_metodos.png)
- 
Archivo generado:  
`comparacion_algoritmos.png`

### 2. Convergencia del Algoritmo Gen√©tico
Gr√°fica que muestra c√≥mo el **fitness promedio y m√°ximo** cambian a lo largo de las generaciones.  
Permite comparar dos tasas de mutaci√≥n:
- Mutaci√≥n baja (0.05)
- Mutaci√≥n alta (0.2)

[Punto_1_convergencia_genetico.png](https://github.com/RogueOne-22/Laboratorio_3/blob/19824c6ea6d83e5b6d96c2f70c8a974ba5beee73/Punto%201/Punto_1_convergencia_genetico.png)
-
Archivo generado:  
`convergencia_genetico.png`

---

## üìä Par√°metros principales
| Par√°metro | Descripci√≥n | Valor |
|------------|--------------|--------|
| `a, b` | Intervalo de b√∫squeda | `[-50, 50]` |
| `n_iter` | Iteraciones Hill/Greedy | `200` |
| `n_generations` | Generaciones GA | `100` |
| `pop_size` | Tama√±o de la poblaci√≥n GA | `30` |
| `mutation_rate` | Tasa de mutaci√≥n GA | `0.05` y `0.2` |
## üß¨ Implementaci√≥n del Algoritmo Gen√©tico

El **Algoritmo Gen√©tico ** es una t√©cnica inspirada en la evoluci√≥n biol√≥gica que busca aproximar la mejor soluci√≥n posible a un problema.  
---

### ‚öôÔ∏è Etapas principales del Algoritmo

1. **Inicializaci√≥n de la poblaci√≥n**
   - Se generan aleatoriamente varios valores de \(x\) dentro del rango \([a, b]\).
   - Cada individuo representa una posible soluci√≥n al problema.

   ```python
   population = np.random.uniform(a, b, pop_size)
   ```

2. **Evaluaci√≥n del fitness**
   - Cada individuo es evaluado con la funci√≥n objetivo.
   - El valor de fitness corresponde directamente a \( f(x) \).

   ```python
   fitness = f(population)
   ```

3. **Selecci√≥n**
   - Se utiliza el **m√©todo de torneo**: se eligen dos individuos al azar y se conserva el que tenga mayor fitness.
   - Este proceso se repite hasta llenar la poblaci√≥n de padres.

   ```python
   i, j = np.random.randint(0, pop_size, 2)
   parents.append(population[i] if fitness[i] > fitness[j] else population[j])
   ```

4. **Cruce (recombinaci√≥n)**
   - Se combinan dos padres para generar descendientes.
   - En este caso, se usa un **cruce promedio** (promedio de los valores de los padres).

   ```python
   child1 = (p1 + p2) / 2
   child2 = (p1 + p2) / 2
   ```

5. **Mutaci√≥n**
   - Con una cierta probabilidad (`mutation_rate`), se altera ligeramente el valor de algunos descendientes.
   - Esto mantiene la diversidad gen√©tica y evita la convergencia prematura.

   ```python
   mutation_mask = np.random.rand(pop_size) < mutation_rate
   offspring[mutation_mask] += np.random.uniform(-1, 1, np.sum(mutation_mask))
   offspring = np.clip(offspring, a, b)
   ```

6. **Actualizaci√≥n**
   - La nueva generaci√≥n reemplaza a la anterior.
   - Se guarda el **mejor fitness** de cada generaci√≥n para analizar la convergencia.

   ```python
   fitness_history.append(np.max(fitness))
   population = offspring
   ```

---

### üìà Visualizaci√≥n de la convergencia

El algoritmo se ejecuta durante **100 generaciones** con **dos tasas de mutaci√≥n diferentes** (`0.02` y `0.15`).  
Se grafica la evoluci√≥n del fitness m√°ximo alcanzado en cada generaci√≥n para observar la **convergencia del algoritmo**:

```python
plt.plot(ga1_fit, label='Mutaci√≥n 0.02')
plt.plot(ga2_fit, label='Mutaci√≥n 0.15')
plt.title('Convergencia del fitness en el algoritmo gen√©tico')
plt.xlabel('Generaciones')
plt.ylabel('M√°ximo fitness alcanzado')
plt.legend()
plt.grid(True)
plt.savefig("Punto_1_convergencia_genetico.png", dpi=300)
plt.show()
```

El resultado es una gr√°fica que muestra c√≥mo el algoritmo mejora progresivamente las soluciones hasta estabilizarse en el m√°ximo global de la funci√≥n.


## üì¶ Ejemplo Resultado
<img width="196" height="84" alt="imagen" src="https://github.com/user-attachments/assets/c8cc58c6-fcd3-4f7c-82dc-de9b33d2fe87" />

---

## üß≠ Conclusi√≥n

Los tres m√©todos convergen al mismo m√°ximo global dentro del intervalo dado, pero:
- **Hill Climbing** puede atascarse si el paso es muy grande.  
- **Greedy Search** explora mejor el entorno.  
- **Gen√©tico** ofrece mayor robustez y control mediante par√°metros (mutaci√≥n, cruce, generaciones).

---

## ‚ú® Autor
**Paula S**  

